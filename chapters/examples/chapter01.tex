\chapter{Introduction}
\label{ch:intro}
In recent decades , the digital era has placed growing pressure on businesses to adapt. In order to remain competitive companies need to go through digital transformations to ensure survival. This can be achieved through effective integration of digital processes in their day-to-day operations \cite{kraus:2021} . One of the key drivers of this transformation is data.

%
% Section: Motivation
%
\section{Motivation}
\label{sec:intro:motivation}
\graffito{Background: Digital Transformation and the Role of Data}
Industries are increasingly leveraging data as a key source for decision-making , training Machine Learning/ Deep Learning models, delivering reports and extracting useful business insights \cite{munappy:2020}. Academia has studied this topic and has begun exploring how data can add value to the decision-making process across different industries and settings. Several domain-specific areas have already started using data such as healthcare , manufacturing and finance \cite{ahmed:2023} \cite{dubey:2019} \cite{heaton:2017} . Companies are witnessing a management revolution , where they are changing how decisions are made in organization. Through the use of data , artificial intelligence and analytics they are able to do more precise measurements, stronger predictions and faster more-informed decisions than traditional methods. Using large and diverse data sets allows them to forecast and detect trends that were not possible before , moving from intuition to evidence-based decision making [9].

\smallskip


\graffito{Industry Examples: Data Pipelines and AI in Practice}
For instance a company that handles billing data for their clients , is using data pipelines that takes raw billing files and transforms them into structured tables ready for analytics tools. With this prepared data they can test their prediction models to see if they could forecast when customers might change their providers \cite{gagliardelli:2023} . Platforms like Amazon are using Ai pipelines to analyze customer behavior and transaction history in real time for custom product suggestions. \cite{vangibhurathachhi:2025}. These practical examples illustrate the significance of leveraging data for solving real business use-cases and demonstrates the importance of designing such data pipelines that are adaptable and can evolve with changing requirements


%
% Section: Ziele
%
\section{Challenges in ML System Development}
\label{sec:intro:goal}
Previous research emphasizes that gaining value from data analytics depends on how well companies orchestrate their available resources within the organization \cite{gupta:2016}. Since data technologies and processes are still relatively new, organizations have not yet developed standard methods on how to implement such data solutions. It is consequently essential that firms remain persistent and allow sufficient time and resources for these initiatives to yield the desired result. In order to achieve their desired data-driven goals, companies need to invest substantial resources in their data initiatives. While data and capital is the foundation of data-driven applications, organizations must also utilize their complementary resources such as human resources, managerial alignment and as well training for a data-driven culture \cite{gupta:2016}. Even with sufficient investment and organizational alignment , companies still face technical difficulties in building data-driven systems. Developing a machine learning (ML) system raises unique challenges compared to traditional software engineering \cite{arpteg:2018}. Unlike conventional systems , where functionality is explicitly programmed, in ML pipelines these systems rely on data to automatically shape system behavior. As a result , the performance of a model remains uncertain until it is evaluated with a representative dataset, which creates additional complexity in project planning. Further difficulties also arise from lack of transparency in data, coupling of components inside large architectures and performance degradation when specific components are changed \cite{giray:2021}. These issues make it difficult to accurately estimate development effort or resource allocation for these requirements

\section{Model Lifecycle Management}
\label{sec:intro:lifecycle}
Another critical aspect that comes with building such complex ML pipelines is experiment management. A typical development of ML systems usually involves running a large number of experiments to identify optimal models. Because each experiment may vary in configuration, data or hyperparameters, ensuring reproducibility becomes an essential part of development. This requires careful tracking of components such as libraries used , model version and datasets to guarantee consistent and verifiable results across iterations. Moreover ML models are highly sensitive to data distribution shifts, or also known as concept drift , which can quickly degrade predictive performance of an ML Model. As real-world data evolves, models must be retrained to preserve their accuracy and reliability \cite{steidl:2023}. This necessity introduces further complexity, as now organizations must establish mechanisms in place not only to make their pipelines robust but to ensure that it is adaptable to data drifts.

%
% Section: Struktur der Arbeit
%
\section{Objective}
\label{sec:intro:objective}
This thesis will address these challenges by proposing the design of a modular data pipeline with embedded continuous learning, while also being generalized across different domains where classification is central. The modular design will focus on decoupling the pipeline components \cite{sculley:2015} so that changes in one part do not propagate across the entire system, therefore reducing complexity and maintainability. To demonstrate its applicability and validate its relevance , the pipeline will be narrowed down to a classification pipeline, so it can be applied to a real-world business use case. While the work remains theoretical and involves partial technical implementation , the use case serves as a theoretical approach to illustrate how the proposed framework could address enterprise level requirements in practice.
\smallskip

In doing so , this thesis contributes both theoretically, by advancing academic discussions on modular architectures and continuous learning in ML pipelines, as well as practically , by offering enterprises a blueprint for designing data-driven systems that are adaptable and suitable for real-world deployment in dynamic business environments.


