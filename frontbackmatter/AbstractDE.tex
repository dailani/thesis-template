%*******************************************************
% Abstract in German
%*******************************************************
\begin{otherlanguage}{ngerman}
    \pdfbookmark[0]{Zusammenfassung}{Zusammenfassung}
    \chapter*{Zusammenfassung}
    Heutzutage verlagern Unternehmen ihre Entscheidungsfindung immer stärker hin zu datengetriebenen Ansätzen. Sie nutzen diese Daten, um Anwendungen aufzubauen, die sie mit Business Intelligence unterstützen. Dadurch können sie geschäftliche Herausforderungen effektiver angehen, die Effizienz verbessern und die Profitabilität steigern. Das zentrale Problem bei der Erreichung dieser Vorteile liegt jedoch in der Fülle der Daten und der Form, in der sie vorliegen. Die Umwandlung von Rohdaten in nützliche Erkenntnisse erfordert Zeit und Ressourcen. Wenn Unternehmen solche Lösungen entwickeln, ändern sich die Anforderungen häufig im Laufe der Zeit. Abhängig von den getroffenen Architekturentscheidungen lassen sich diese Lösungen möglicherweise nicht leicht an Veränderungen anpassen, wodurch Unternehmen gezwungen sind, noch mehr Ressourcen für Anpassungen aufzuwenden. Das macht den Aufbau und die Wartung solcher Systeme kostspielig und komplex. Darüber hinaus verlassen sich viele Unternehmen auch auf KI-Modelle oder Algorithmen des maschinellen Lernens, um tiefere Erkenntnisse aus Rohdaten zu gewinnen und sie in gelabelte Daten zu überführen. In einigen Fällen müssen diese Modelle zudem auf Basis von Echtzeitdaten angepasst werden, um ihre Genauigkeit kontinuierlich zu verbessern. Was als einfacher ETL-Prozess beginnt, entwickelt sich daher zu einem Datenklassifikationsproblem mit kontinuierlichem Lernen als zusätzlicher Schicht. Diese Lösung besteht aus mehreren eng gekoppelten Modulen, was bedeutet, dass eine Änderung in einem Modul die anderen direkt beeinflusst und zusätzliche Komplexität erzeugt.
    \smallbreak

    Diese Arbeit konzentriert sich darauf, das zuvor beschriebene Problem durch die Gestaltung einer modularen Datenklassifikations-Pipeline mit kontinuierlichem Lernen anzugehen. Diese Forschung wird durch eine systematische Literaturrecherche unterstützt, um die relevantesten und modernsten verfügbaren Lösungen zu identifizieren. Die vorgeschlagene Architektur wird anschließend anhand eines realen Anwendungsfalls aus der Unternehmenspraxis validiert, um ihre Wirksamkeit unter praktischen Bedingungen zu demonstrieren.
    \smallbreak

    Diese Datenklassifikations-Pipeline ist ein relativ neuer Ansatz, der durch ihre modulare Architektur häufige Anpassungen innerhalb des Systems ermöglicht und so signifikante Ergebnisse liefern kann. Das Ergebnis wird ein zuverlässiges Design einer Datenklassifikations-Pipeline sein, das anpassungsfähig gegenüber Veränderungen ist und reale Herausforderungen wirkungsvoll adressiert.

\end{otherlanguage}
